# 用于日志目录命名：logs/<checkpoint>_<timestamp>/
checkpoint: "INR_SR_Scheme2_v12"

# -----------------------
# Dataset roots (for CLAM slicing/export)
# train.py 会构建 image_dict 并调用 slic_tool.run_clam_and_export
# -----------------------
TCGA_LUAD:
  root: "/mnt/lwx/pyworkspace/multi-sur/data/TCGA-LUAD/"
  choose_WSI: 50

TCGA_KIRC:
  root: "/mnt/lwx/pyworkspace/multi-sur/data/TCGA-KIRC/"
  choose_WSI: 50

TCGA_LIHC:
  root: "/mnt/lwx/pyworkspace/multi-sur/data/TCGA-LIHC/"
  choose_WSI: 50

# -----------------------
# Data loader / preprocessing settings
# 这些字段在 train.py 中被直接读取
# -----------------------
data_loader:
  # 是否跳过切片导出（重要：train.py读取的是 data_loader.skip_slicing）
  skip_slicing: false

  # 输出目录（必须符合 loader.py 读取约定）
  # out_img_dir/
  #   hr_png/<slide_id>/patch_xxx.png
  #   lr_png/<slide_id>/patch_xxx.png
  #   clinical.tsv
  out_img_dir: "/mnt/liangjm/SpRR_data/"

  # CLAM 切片导出参数
  patch_size: 512
  step_size: 512
  patch_level: 0
  down_scale: 4
  min_tissue_ratio: 0.5

  # 数据加载
  num_workers: 8
  pin_memory: true

  # 控制随机性 & split
  seed: 2025
  patch_num: 200
  train_ratio: 0.7
  val_ratio: 0.1
  test_ratio: 0.2

# -----------------------
# Model settings (方案2：不依赖DINO/HoVer)
# train.py 会用这些超参构建 SRModelConfig / SRModel
# -----------------------
model:
  # =====================================================
  # Basic SR & kernel prediction
  # =====================================================
  scale: 4

  feat_ch: 64
  pe_bands: 10
  mlp_hidden: 256
  mlp_depth: 5

  kernel_size: 7
  kernel_allow_negative: true

  num_points: 4096
  saliency_ratio: 0.7
  loss_alpha: 3.0

  # =====================================================
  # Residual SR & color preservation
  # =====================================================
  use_residual: true
  use_res_refiner: true

  # =====================================================
  # Gradient consistency (base)
  # =====================================================
  lambda_grad: 0.1
  grad_crop: 128

  # =====================================================
  # FFT consistency (optional, default off)
  # =====================================================
  lambda_fft: 0.0
  fft_crop: 256
  fft_cutoff_ratio: 0.15
  fft_use_logmag: true

  # =====================================================
  # Inference chunking
  # =====================================================
  infer_chunk: 8192

  # =====================================================
  # Tau annealing (kernel softmax temperature)
  # =====================================================
  tau_start: 1.0
  tau_end: 0.5
  tau_warm_epochs: 2
  tau_anneal_epochs: 8

  # =====================================================
  # HoVer-Net maps (used in loss & sampling)
  # =====================================================
  use_hover: true

  hover_sample_ratio: 0.5
  hover_bnd_sigma: 2.0
  hover_mask_sigma: 1.5
  hover_bnd_weight: 2.0
  hover_in_weight: 0.5

  lambda_hover_grad: 0.2
  lambda_in_gray: 0.05

  # =====================================================
  # HoVer condition injection (TRAIN ONLY, Scheme C)
  # =====================================================
  use_hover_cond: true
  hover_cond_bnd: true
  hover_cond_mask: true

  hover_cond_strength: 1.0
  hover_cond_blur_lr: 0.0

  # condition dropout: crucial for validation without hover
  hover_cond_dropout: 0.5

  # =====================================================
  # Teacher–Student consistency (core sharpening driver)
  # =====================================================
  lambda_cond_consistency: 0.15
  cond_consistency_crop: 192
  cond_consistency_hp_sigma: 1.5


# -----------------------
# Trainer settings
# -----------------------
trainer:
  epochs: 50
  batch_size: 8
  lr: 1.0e-4
  weight_decay: 1.0e-4
  grad_clip: 1.0
  log_every: 50
  use_amp: true

# -----------------------
# Validation / checkpoint / visualization
# -----------------------
validator:
  do_val: true
  max_batches: -1
  metric_for_best: "lpips"
  best_mode: "min"

  # 每轮验证保存一张随机可视化：HR / LR_up / SR 拼接图
  save_vis: true
  vis_subdir: "val_vis"
